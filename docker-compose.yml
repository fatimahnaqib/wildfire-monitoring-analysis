services:
  # -------------------------------
  # Ingestion Service (NASA FIRMS fetch)
  # -------------------------------
  ingestion:
    build:
      context: .
      dockerfile: ./services/ingestion/Dockerfile
    container_name: wildfire_ingestion
    ports:
      - "8000:8000"
    environment:
      - AIRFLOW_DATA_DIR=/data
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=wildfire_data
    volumes:
      - ./airflow/data:/data
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy

  # -------------------------------
  # Producer Service (Kafka producer)
  # -------------------------------
  producer:
    build:
      context: .
      dockerfile: ./services/producer/Dockerfile
    container_name: wildfire_producer
    ports:
      - "8001:8001"
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=kafka:9092
      - KAFKA_TOPIC=wildfire_data
      - AIRFLOW_DATA_DIR=/data
    volumes:
      - ./airflow/data:/data
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy

  # -------------------------------
  # Consumer Service (Kafka consumer with health/metrics)
  # -------------------------------
  consumer:
    build:
      context: .
      dockerfile: ./services/consumer/Dockerfile
    container_name: wildfire_consumer
    ports:
      - "8002:8002"
    environment:
      - KAFKA_BROKER=kafka:9092
      - KAFKA_TOPIC=wildfire_data
      - KAFKA_GROUP_ID=wildfire_group
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=wildfire_db
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_healthy

  # -------------------------------
  # Map Service (Wildfire visualization)
  # -------------------------------
  map:
    build:
      context: .
      dockerfile: ./services/map/Dockerfile
    container_name: wildfire_map
    ports:
      - "8003:8003"
    environment:
      - POSTGRES_HOST=postgres
      - POSTGRES_PORT=5432
      - POSTGRES_DB=wildfire_db
      - POSTGRES_USER=airflow
      - POSTGRES_PASSWORD=airflow
      - AIRFLOW_DASHBOARD_DIR=/dashboard
    volumes:
      - ./airflow/dashboard:/dashboard
    depends_on:
      postgres:
        condition: service_healthy

  # -------------------------------
  # PostgreSQL for Airflow & Wildfire DB
  # -------------------------------
  postgres:
    image: postgres:14
    container_name: wildfire_postgres
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./postgres/init/init.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Kafka (KRaft mode - no Zookeeper needed)
  kafka:
    image: bitnami/kafka:latest
    container_name: wildfire_kafka
    ports:
      - "9092:9092"
    environment:
      - KAFKA_KRAFT_MODE=true
      - KAFKA_CFG_NODE_ID=1
      - KAFKA_CFG_PROCESS_ROLES=broker,controller
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=1@wildfire_kafka:9093
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CFG_LOG_DIRS=/bitnami/kafka/data
    volumes:
      - kafka_data:/bitnami/kafka
    healthcheck:
      test: ["CMD-SHELL", "kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Standalone Kafka consumer (creates topic if needed)
  kafka_consumer:
    build: ./kafka_consumer
    container_name: wildfire_kafka_consumer
    depends_on:
      kafka:
        condition: service_healthy
      postgres:
        condition: service_started
    restart: always

  # -------------------------------
  # Apache Airflow Webserver
  # -------------------------------
  # Shared Airflow environment variables
  x-airflow-common: &airflow-common
    build:
      context: .
      dockerfile: ./airflow/Dockerfile
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: SequentialExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres:5432/airflowdb
      AIRFLOW__WEBSERVER__EXPOSE_CONFIG: True
      PYTHONPATH: /opt/airflow
    volumes:
      - ./airflow:/opt/airflow
      - ./airflow/requirements.txt:/requirements.txt

  airflow-webserver:
    <<: *airflow-common
    container_name: airflow_webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:8080/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 5

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow_scheduler
    command: scheduler
    depends_on:
      airflow-webserver:
        condition: service_healthy

  airflow-init:
    <<: *airflow-common
    entrypoint: /bin/bash
    command: -c "airflow db init && airflow users create --username admin --firstname admin --lastname admin --role Admin --email admin@example.com --password admin"

volumes:
  postgres_data:
  kafka_data:
